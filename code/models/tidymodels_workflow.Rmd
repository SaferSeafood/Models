---
title: "Tidymodels Testing"
author: "SaferSeafood"
date: "2024-03-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)

library(rfishbase)
library(tidyverse)
library(tidymodels)
library(multilevelmod)
library(rstanarm)
```

## Overview

---

### Summary of document

This document contains model testing using a machine learning approach to test predictive accuracy of our chosen model (updated model with non lipid-normalized data). The decisions to choose a model formula can be found in the BRMS_testing.Rmd file in the same folder.

This document contains code and text describing the testing process. This document does not contain the final model, just the process of testing the model formula using training and testing datasets.

### Highlights

* Read in data/prep

**Modeling Family and Species as Random Effects**

* Create model spec
* Create workflow
* Train model with training data 
* Predict on test data
* Metrics

---

## Code

**READ IN DATA/PREP**

```{r}
# READ IN DATA ----
# read in cleaned data
fish_cleaned <- read_csv(here::here("data", "data_outputs", "ddx_southernCA_norm.csv"))

# DATA SPLITTING ---- 
# split new data
fish_split <- initial_split(fish_cleaned, prop = 0.7)
fish_train <- training(fish_split)
fish_test <- testing(fish_split)
```

### MODELING FAMILY and SPECIES AS RANDOM EFFECTS

**Create spec**

```{r}
# create spec
brm_fish_spec <- linear_reg() %>% 
  set_engine("stan_glmer", 
             prior_intercept = rstanarm::cauchy(0, 0.5)) %>%
  set_mode("regression")
```

**Create workflow**

Create two separate workflows, one with family and one with species as a random effect. We want to understand whether using family as a predictor rather than species has a higher predictive power in the case that a fisherman catches a species outside of our list. The format of this step is suggested by the multilevelmod documentation.

```{r}
# this is the workflow suggested by multilevelmod 
# family workflow
fam_wflow <- 
  workflow() %>% 
  add_variables(outcomes = TotalDDT.trans.non, predictors = c(TotalDDT.sed.trans, trophic_category, TotalDDT.sed.trans, feeding_position, Year, Family)) %>% 
  add_model(brm_fish_spec, formula = TotalDDT.trans.non ~ TotalDDT.sed.trans * trophic_category + TotalDDT.sed.trans * feeding_position + Year + (1|Family))

# species workflow
species_wf <-  workflow() %>% 
  add_variables(outcomes = TotalDDT.trans.non, predictors = c(TotalDDT.sed.trans, trophic_category, TotalDDT.sed.trans, feeding_position, Year, CompositeCommonName)) %>% 
  add_model(brm_fish_spec, formula = TotalDDT.trans.non ~ TotalDDT.sed.trans * trophic_category + TotalDDT.sed.trans * feeding_position + Year + (1|CompositeCommonName))
```

**Train each model with training data**

```{r}
# fit family model
brm_fam_fit <- fam_wflow %>% 
  fit(data = fish_train) 

# fit species model
brm_species_fit <- species_wf %>% 
  fit(data = fish_train)
```

**Predict on test data**

Use our model to make predictions on test data.

```{r}
# prediction for family model ----
# get predictions
test_predict_fam <- predict(brm_fam_fit, fish_test) %>% #get prediction probabilities for test data
  bind_cols(fish_test)

# get prediction interval and add it to the predictions
predict_species_int <- predict(brm_fam_fit, fish_test, type = "pred_int") %>% 
  bind_cols(test_predict_fam)

# prediction for species model ----
test_predict_species <- predict(brm_species_fit, fish_test) %>% 
  bind_cols(fish_test)

# get prediction interval and add it to the predictions
predict_fam_int <- predict(brm_species_fit, fish_test, type = "pred_int") %>% 
  bind_cols(test_predict_fam)
```

**METRICS**

Get the model performance for our test data predictions.

```{r}
randomfam <- metrics(test_predict_fam, truth = TotalDDT.trans.non, estimate = .pred)
randomspecies <- metrics(test_predict_species, truth = TotalDDT.trans.non, estimate = .pred)

randomfam
randomspecies
```

## Results/Overview

Using this approach allowed us to understand the predictive power on 30% of the data. The knitted document may have varying results as the data splitting is random each time. However, the general results show that the model that uses species as a random effect does, in fact, perform better than the model using family as a random effect. The R squared value of this model is comparable to the brms model R squared, which confirms our choice and robustness of our model choice. 

